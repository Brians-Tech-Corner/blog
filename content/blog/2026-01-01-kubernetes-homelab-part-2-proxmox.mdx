---
title: "Kubernetes Homelab: Proxmox for a Realistic Kubernetes Homelab (VLANs, Networking, and Gotchas)"
description: "How I set up Proxmox and UniFi networking to support a production-like Kubernetes homelab, including VLANs, firewall pitfalls, and lessons learned."
date: "2026-01-03"
series: "kubernetes-homelab"
seriesOrder: 2
tags: ["proxmox", "kubernetes", "homelab", "unifi", "networking", "vlan"]
draft: true
---

If you want to run Kubernetes at home **in a way that actually resembles production**, Proxmox is an excellent foundation — but only if you get the networking right.

This post covers everything that happened **before Kubernetes even entered the picture**: Proxmox installation, VLAN design, UniFi switch configuration, firewall pitfalls, and the mistakes that caused hours of head-scratching.

This is **Part 1** of a multi-part series where I build a production-like Kubernetes homelab on Proxmox.

---

## Why Proxmox?

I wanted a setup that:

- Supports multiple Kubernetes nodes
- Uses real networking, not host-only shortcuts
- Forces me to debug routing, ingress, and firewall rules
- Feels close to what you’d see in enterprise environments

Proxmox checks all of those boxes:

- Bare-metal hypervisor
- Strong, explicit networking model
- ZFS built in
- Great UI and CLI

Most importantly, Proxmox doesn’t hide complexity — which is exactly what you want when learning Kubernetes seriously.

---

## Hardware Overview

- Mini PC running Proxmox VE
- NVMe storage for VM disks
- ZFS configured during install
- Additional ZFS pool created for Kubernetes workloads

All Kubernetes nodes run as **VMs**, not LXC containers.

This is intentional. LXC skips too many layers that matter for Kubernetes internals and certification-style learning (CKA/CKAD).

---

## Networking Design (This Is the Critical Part)

### VLAN Strategy

I created a **dedicated Kubernetes VLAN**:

- VLAN ID: `30`
- Subnet: `192.168.30.0/24`
- Gateway / DHCP: UniFi router

Why a separate VLAN?

- Mirrors real production environments
- Forces proper routing and firewall thinking
- Prevents “everything works because it’s flat” setups
- Makes ingress and service exposure meaningful

All Kubernetes nodes live **only** on this VLAN.

---

## UniFi Switch Configuration (What Actually Broke Things)

### Mistake #1: Using an Unmanaged Switch

Initially, Proxmox was connected through an unmanaged switch.

This caused subtle but brutal issues:

- VLAN tags were stripped
- Devices appeared on the wrong subnet
- Proxmox UI became intermittently unreachable
- Kubernetes nodes received unexpected IPs

**Unmanaged switches and VLANs do not mix.**

**Fix:** replace it with a managed UniFi switch.

---

### Trunk vs Access Ports (Very Important)

Once the managed switch was in place, port configuration mattered a lot.

#### Uplink Port (Main Switch → Proxmox Switch)

Configured as a **trunk**:

- Native (untagged): default LAN
- Tagged: VLAN 30 (Kubernetes)

#### Proxmox Host Port

Configured as an **access port**:

- Untagged VLAN: `30`
- No VLAN tagging inside Proxmox VM NICs

This is a common mistake: tagging both at the switch *and* inside Proxmox will break connectivity in confusing ways.

---

## Proxmox Network Configuration

### Bridge Setup

Inside Proxmox, I created a VLAN-aware bridge:

- Example: `vmbr30`
- Attached to the physical NIC
- VLAN-aware enabled
- Proxmox itself assigned an IP in `192.168.30.0/24`

One important lesson here:

> A Proxmox bridge must have a physical interface attached.

I hit this error early on:

```text
no physical interface on bridge 'vmbr30'
```

This was caused by:

- Incorrect bridge configuration
- VLAN tagging applied at the VM NIC instead of the switch
- **Proxmox Firewall (Major Gotcha)**

## Proxmox Firewall (Major Gotcha)

This one deserves special attention.

I enabled the Datacenter-level firewall with no rules.

**The result:**

- Proxmox UI instantly unreachable
- SSH blocked
- Everything appeared “dead”

Nothing was actually broken — I had just locked myself out.

---

### Correct Firewall Approach

The correct way to use Proxmox firewall:

- Leave Datacenter firewall **disabled**
- Enable firewall at the **Node** level
- Default policy set to **DROP**
- Explicitly allow:
  - Proxmox UI (8006)
  - SSH
  - Required VLAN traffic

This gives you realistic security without bricking your host.

---

## What This Setup Enables

After fixing networking and firewall issues, I had:

- Stable Proxmox access on VLAN 30
- Clean separation between home LAN and Kubernetes
- A platform ready for:
  - Multi-node Kubernetes
  - Ingress testing
  - Real routing and firewall behavior

At this point, Proxmox stopped being the problem — which is exactly where you want to be.

---

## Lessons Learned (So Far)

- VLANs expose mistakes early — and that’s a good thing
- Unmanaged switches will silently sabotage you
- Don’t double-tag VLANs (switch or hypervisor, not both)
- Proxmox firewall defaults can lock you out instantly
- If networking is flaky, Kubernetes debugging is impossible

---

## What’s Next

In Part 2, I’ll cover:

- Building a multi-control-plane Kubernetes cluster on Proxmox
- kubeadm installation details
- DNS and hostname pitfalls
- Node roles, taints, and scheduling

If you’re studying for Kubernetes certifications or building a serious homelab, this is where things start to feel real.
